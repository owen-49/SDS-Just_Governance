# 1) 账号与认证

```sql
-- 1. users表：主表，存储账号核心信息

		-- 无论用户是采取注册还是直接第三方登录，每个账户都必须有唯一的user记录。
			-- 简单来说，就是一个账户必定唯一对应一条user记录。
			
		-- 一个主账户可以绑定多个第三方账号，但绑定的前提是要有自己的注册邮箱和密码。
			-- 举两个例子：
			-- 例子1：如果一个用户是直接使用邮箱+密码注册的，那么user表就会创建一条记录。之后，用户还可以选择绑定其他第三方账号，如google,apple。每绑定一个账号，就会在oauth_accounts表中插入一条记录，这些记录通过外键关联到user记录。
			-- 例子2：如果一个用户一开始就直接使用第三方登录，那么oauth_accounts表中会创建一条新记录对应这个第三方账号，但user表必须也创建一条对应记录，因为必须要有一个user记录来对应一个账户。但是此时user记录中的email, password是空的。这个时候，如果用户想让账号更加可靠增强主控权，或者想绑定其他第三方账号，就必须事先绑定一个自己的邮箱并创建密码（需要像注册的时候一样验证），也就是说，原来的user记录中会插入email, password。绑定了自己的邮箱之后，用户才可以继续为这个账号绑定其他第三方账号（所有账号都对应同一个平台账户）。
			
		-- 这样设计的目的是一避免单点故障,	防止某个第三方账号突然不受支持，或者用户的第三方账号突然失效冻结等。其次，多个第三方账号有助于方便用户快捷登录。需要注意的是第三方账号的作用其实就是方便用户快捷登录（不用输密码）或者第一次进入平台方便，并不能代替主邮箱进行账户密码修改、忘记密码找回等。
		
		-- 此外，用户的主邮箱（注册邮箱）一旦设定，便不可更改。这是一种简化保守的设计。因为一旦邮箱可以更改，万一用户的邮箱被盗，那么他人便可借此修改密码甚至更改主邮箱，解除第三方账号的绑定等，会导致账户完全被窃取。相反，如果用户的主邮箱不可变，那么即便用户的主邮箱被盗，由于邮箱账号往往有高安全性，用户容易找回，因此只要平台的账户始终绑定着这个主邮箱，那么就能保证这个账户最终能回到用户手中。
        
		-- 因此，除了注册、登录之外，该模块的核心功能实现包括不限于这么几个：验证主邮箱、修改密码、忘记密码、绑定和解绑第三方账号等。
		-- 1. 邮箱验证：
			-- 发生在：用户用邮箱注册而不使用第三方登录，或者用户已经在使用第三方账号登录，但是仍然要创建主邮箱的情况。系统发送链接到用户主邮箱，用户去主邮箱点击链接跳转，输入新密码。
		-- 2. 修改密码：
			  -- 用户可以去个人中心点击修改密码。有两种方式：
			-- 方式一.填写旧密码，输入新密码，重复输入新密码。
			-- 方式二.【邮箱验证】
		-- 3. 忘记密码：							
			  -- 发生在登录页面
			  -- 同理，用户去【邮箱验证】
		-- 如果用户没有创建主账号，根本不存在什么密码，总是靠第三方登录。账号的安全性完全依赖于google/apple等账号的安全性和可靠性。上面的功能2、3就用不到。
		-- 4. 绑定和解绑第三方账号。
		-- 5. 注册、邮箱验证、第三方关联的具体原理流程在下面有讲。


CREATE TABLE users (
  id UUID PRIMARY KEY,
  email TEXT UNIQUE,		-- 用户的注册邮箱（必须唯一，否则会出现多个账号绑定同一个邮箱的情况）
  email_verified_at TIMESTAMPTZ,  -- 邮箱第一次被验证的时间
  password_hash TEXT,                  -- 存储密码需要使用哈希不可逆加密。当用户登录输入密码时，采用相同的密钥和哈希算法计算结果然后与数据库中所存进行比对即可。
    
  name TEXT,	
  avatar_url TEXT, -- 用户头像的网络地址，用于展示用户的头像。
  ... -- 还有一些其他基本信息没有列举
    
  first_login_at TIMESTAMPTZ,						-- 第一次登录时间（如果为null说明还没登录过，第一次登录需要展示项目介绍弹窗）
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),	-- 账户创建的时间
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now()		-- 账户信息更新的时间
);


-- 2.oauth_accounts表：用于存储一个用户的多个外部身份（即第三方身份）
CREATE TABLE oauth_accounts (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  provider TEXT NOT NULL,              -- google/microsoft/linkedin/apple
  provider_account_id TEXT NOT NULL,	-- 第三方会给每个自己的账号唯一的id
    
  UNIQUE(provider, provider_account_id) -- 唯一约束：防止同一个第三方账号被多个平台账号绑定，否则第三方登录竟然不知道要登哪一个user账号
);
	-- 以下通过两个场景来展示第三方账号的关联和绑定：
        -- 场景1：第一次不使用邮箱注册，直接使用第三方账号登录
        	-- 用户点击“使用 Google 登录”
        	-- 成功跳转并授权 → 系统拿到：provider = 'google' provider_account_id = '123456abcdef'（可选）OAuth 提供的姓名、头像等
        	-- 系统查询：SELECT * FROM oauth_accounts WHERE provider = 'google' AND provider_account_id = '123456abcdef'
        	-- 没查到 → 说明用户是第一次用这个 OAuth 登录
        	-- 创建一条新的 users 记录（邮箱、密码字段为空），创建一条新的 oauth_accounts 记录，指向该用户
        -- 场景2：用户已经注册了邮箱账号，现在要绑定一个 Google 账号	
        	-- 用户点击「绑定 Google」
        	-- 成功授权后返回：
        	-- 系统获得 provider_account_id
        	-- 系统查询该 (provider, provider_account_id) 是否已存在
        	-- ✅ 不存在 → 插入 oauth_accounts 新记录，指向当前登录的 user_id
        	-- ❌ 存在 → 提示“此 Google 账号已绑定其他用户”

-- 3.邮箱验证
CREATE TABLE email_verification_tokens (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,	-- 哪个用户
  token TEXT UNIQUE NOT NULL,	
  expires_at TIMESTAMPTZ NOT NULL,	-- 超时则token失效，需要重新验证
  used_at TIMESTAMPTZ	-- token是否已经使用过
);
	-- 邮箱验证流程（用于主邮箱注册）：
	-- 点击验证邮箱时，后端为当前的user生成一条token记录，然后为发送验证邮件，其中包含链接，如：https://yourapp.com/verify-email?token=abc123xyzTOKEN。
	-- 用户点击链接，前端调用接口，如：GET /api/verify-email?token=abc123xyzTOKEN。后端流程：查找 token：SELECT * FROM email_verification_tokens WHERE token = 'abc123xyzTOKEN';
	-- 校验逻辑：
	-- 条件	检查字段
	-- token 是否存在	SELECT 是否返回结果
	-- 是否过期	expires_at > now()
	-- 是否已用过	used_at IS NULL
	-- 如果验证通过：
		-- 设置该 token 的 used_at = now()
		-- 更新 users.email_verified_at = now() → 表示该用户邮箱已验证
		-- 返回“验证成功”，引导用户进入首页或登录

-- 4.找回密码
	-- 用于“通过邮箱验证找回密码”的情况
	-- 本质上仍然是使用主邮箱验证，区别是验证的结果是修改设置新密码
	-- 实践中一般都分两个表维护，因为可能要更复杂的安全管理。这里简化。
CREATE TABLE password_reset_tokens (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  token TEXT UNIQUE NOT NULL,
  expires_at TIMESTAMPTZ NOT NULL,	-- 超时则token失效，需要重新验证
  used_at TIMESTAMPTZ -- token是否已经使用过
);
```

------



# 2) 学习信息架构（四大板块→模块→主题）

```sql
CREATE TABLE boards (                 -- 四大板块
  id UUID PRIMARY KEY,
  name TEXT NOT NULL,
  sort_order INT NOT NULL DEFAULT 0		-- sort_order用来控制在前端展示的顺序，以下同理
);

CREATE TABLE modules (                -- 模块
  id UUID PRIMARY KEY,
  board_id UUID REFERENCES boards(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  sort_order INT NOT NULL DEFAULT 0
);

CREATE TABLE topics (                 -- 主题
  id UUID PRIMARY KEY,
  module_id UUID REFERENCES modules(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  pass_threshold NUMERIC NOT NULL DEFAULT 0.8,   -- 小测最小通过分数，达到才可标记主题已完成
  sort_order INT NOT NULL DEFAULT 0,
  is_active BOOLEAN NOT NULL DEFAULT TRUE	-- 主题是否启用，如果不启用则不展示在前端
  -- slug 是一种用于 URL 的唯一、可读标识符字符串，通常是英文短语或词组。
    	-- 人类可读，比 UUID 更容易理解、记忆、分享，不暴露数据库 ID
  
    
);
		-- 主题内容
CREATE TABLE topic_contents (
  id UUID PRIMARY KEY,
  topic_id UUID REFERENCES topics(id) ON DELETE CASCADE,

  body_format TEXT DEFAULT 'markdown',         -- 内容格式
  body_markdown TEXT,                          -- 正文：Markdown + 自定义标记
  summary TEXT,                                -- 简短介绍（首页预览用）
  resources JSONB,                             -- [{title, url, source, open_in}]
  
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);
```

------

## 主题的知识内容区究竟如何展示

“主题内容页面”中能做到：

- 有文字、有图、有视频、有小测，**排版顺序自定义**
- 内容在数据库中能维护好
- 页面上能灵活渲染
- 不要乱七八糟地嵌死

### 目前建议方案：Markdown文本 + 自定义标记

可以把**整篇内容写成 Markdown 文本**，**在你想插入视频、小测的地方写“特殊标记”**，前端看到这些标记的时候，自动换成对应组件。

------

#### 举例

数据库里 `body_markdown` 内容可以这样写👇

```markdown
# 主题标题：预算与预测
这是正文第一段。
:::video src="https://cdn.example.com/v/abc.mp4" poster="..." :::
这是视频后的讲解文字。
:::quiz id="inline-quiz-1" topic_id="xxx" :::
这是小测后的总结说明。
```

- `:::video ... :::` → 前端换成视频播放器组件
- `:::quiz ... :::` → 前端换成小测验组件
- 其他是正常 Markdown，自动渲染成文字

------

#### 视频嵌入

```html
<video controls width="600">
  <source src="https://cdn.example.com/video.mp4" type="video/mp4" />
</video>
```

**在 Markdown 里插的 `:::video ... :::`，前端把它换成上面的这个代码，就能正常播放。**

```json
CREATE TABLE topic_contents (
  id UUID PRIMARY KEY,
  topic_id UUID REFERENCES topics(id) ON DELETE CASCADE,

  body_format TEXT DEFAULT 'markdown',         -- 内容格式
  body_markdown TEXT,                          -- 正文：Markdown + 自定义标记
  summary TEXT,                                -- 简短介绍（首页预览用）
  resources JSONB,                             -- [{title, url, source, open_in}]
  
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);
```

# 3) 题库与测试

```sql
CREATE TYPE question_type AS ENUM ('single', 'multi', 'short');

-- 1. questions表：存储所有题目。无论是每个主题的小测，还是主页面测试的题目都从这里来
CREATE TABLE questions (
  id UUID PRIMARY KEY,
  qtype question_type NOT NULL,
  stem TEXT NOT NULL,                   -- 题干
  choices JSONB,                        -- 单选/多选的选项 [{key, text}]
  answer_key JSONB,                     -- 标准答案（含多选/简答要点）
  explanation TEXT,                     -- 答案解析
  rubric JSONB,                         -- 简答评分要点（可提供给AI）
  is_active BOOLEAN DEFAULT TRUE		-- 题目是否投入使用
);

-- 2.question_topics题目主题关联表
CREATE TABLE question_topics (         
  question_id UUID REFERENCES questions(id) ON DELETE CASCADE,
  topic_id UUID REFERENCES topics(id) ON DELETE CASCADE,
  PRIMARY KEY (question_id, topic_id)
);
	-- 一个题目可能涉及多个主题，而一个主题可能涉及多个题目
		-- 当AI分析做题情况时，可据此判断用户薄弱环节
		-- 当生成题目时，需要根据主题搜索响应题目
	-- 因此我们还要加一个反方向的聚合B树索引加快从主题到题目的检索(否则你通过topic_id直接筛选效率极低)
CREATE INDEX idx_question_topics_topic_question
ON question_topics (topic_id, question_id);


CREATE TYPE assessment_kind AS ENUM ('global', 'topic_quiz');

-- 3.评测会话assessment_sessions：所谓一个评测会话，就是在记录一次测试。记录的测试包括大的测试，也包括主题的小测，其中有的字段是只有大测试才用到的。
REATE TYPE assessment_kind AS ENUM ('global', 'topic_quiz');
CREATE TABLE assessment_sessions (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  kind assessment_kind NOT NULL,			  -- global / topic_quiz
  topic_id UUID REFERENCES topics(id),        -- 主题小测时有值
  started_at TIMESTAMPTZ NOT NULL DEFAULT now(), -- 评测开始时间（用于计时、排序、分析）
  submitted_at TIMESTAMPTZ,					  -- 提交时间（未提交为 null，可做“中途退出”判断）
  total_score NUMERIC,                        -- 分数（百分制）
  ai_summary TEXT,                            -- AI 总结
  ai_recommendation JSONB                     -- 学习动线推荐（结构化）
    
  last_question_index INT,	-- 做到哪一题：用于实现大测试的断点续做
);

-- 4.assessment_items表：测试题目表：-- 说白了就是每个测试记录中的所有题目都存储在这。
    CREATE TABLE assessment_items (
      id UUID PRIMARY KEY,
      session_id UUID REFERENCES assessment_sessions(id) ON DELETE CASCADE,
      order_no INT NOT NULL,
      question_snapshot JSONB NOT NULL            -- {qtype, stem, choices, answer_key, rubric...}
    );
-- 之所以不直接在session中按json存储测试题目信息或直接存储question_id，有以下原因：
		-- 其一，理论上题库是可以修改的，如果用原题目可能就错乱了；
		-- 其二，不适合查询与分析：无法高效按题目排序/分页（比如 order_no）
		-- 其三：违反数据库范式：session 是评测整体，item 是评测中每道题，两者粒度不同；一个 session 里有多个 item，属于典型的 1:N 关系，拆表更自然。未来如果每题还要加标签、题目得分、答题时长、AI点评等，都得往这个数组里塞，非常难维护和查询。

CREATE TABLE assessment_items (
  id UUID PRIMARY KEY,
  session_id UUID REFERENCES assessment_sessions(id) ON DELETE CASCADE,
  order_no INT NOT NULL,
  question_snapshot JSONB NOT NULL            -- {qtype, stem, choices, answer_key, rubric...}
);

-- 	5. 用户作答与评分assessment_responses：
-- 如果说items存的是题目的静态快照，那么responses就对应每道题目的用户动态作答。每条response和每条item是一一对应的。
CREATE TABLE assessment_responses (
  id UUID PRIMARY KEY,
  session_id UUID REFERENCES assessment_sessions(id) ON DELETE CASCADE,
  item_id UUID REFERENCES assessment_items(id) ON DELETE CASCADE,
  answer JSONB,                               -- 用户答案
  is_correct BOOLEAN,                         -- 客观题
  score NUMERIC,                              -- 打分
);

CREATE INDEX ON assessment_items(session_id);	-- 建立索引
CREATE INDEX ON assessment_responses(session_id);	-- 建立索引
```

------



# 4) 主题进度与小测情况

```sql
CREATE TYPE progress_status AS ENUM ('not_started','in_progress','completed');
CREATE TYPE quiz_state AS ENUM ('none', 'pending', 'completed');

-- 主题进度表：每个用户每个主题都有一个进度：刚开始，正在进行或者已完成（需用户手动标记）
CREATE TABLE user_topic_progress (
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,			-- 用户id
  topic_id UUID REFERENCES topics(id) ON DELETE CASCADE,		-- 主题id
  progress_status progress_status NOT NULL DEFAULT 'not_started',	-- 主题进度
  last_score NUMERIC,	-- 上一次小测得分
  attempt_count INT DEFAULT 0,  -- 用户提交小测次数
  best_score NUMERIC,	-- 最佳小测得分，只有best_score >= topic_threshold，用户才可标记completed
    
  last_quiz_session_id UUID REFERENCES assessment_sessions(id),	-- 上一次小测记录
  pending_quiz JSONB,     -- 当前小测的题目id
    		-- 示例：{
                    "question_ids": [
                        "32226c86-a6e4-4ae7-889d-69fe776f9a95",
                        "184a9422-ef0f-4070-a8c7-c871b85d2b3d",
                        "5b7e5b12-188a-4b36-aaa3-9d84cb3ddf19"
                      ]
    			    }
  quiz_state quiz_state NOT NULL DEFAULT 'none',    
    		-- 表示当前做题状态
    -- 详细解释：
    -- state为none表示用户还没打开过主题的小测栏，题目甚至都还没有生成。
    -- 当用户打开主题的小侧栏，则后端随机生成题目，生成的题目id存储到pending_quiz中，此时quiz_state的值变为pending。
    -- 用户只要没有点击“提交”，那么当前的小测就不会记录到assessment_sessions表中，即便用户已经填写了一些题目；如果中途刷新页面，做题进度会丢失，但是刷新后打开页面小测题目还是原来的题目，因为题目的id已经存储到pending_quiz中了，不会重新生成一遍。
    -- 当用户点击“提交”，则立刻根据当前小测结果生成一条assessment_session记录，修改quiz_status为completed状态。当status为completed时，小测界面不再展示pending_quiz的内容，而是显示last_quiz_session_id对应的assessment_session的内容，也就是：题目、用户答题状态、答案和解析等。只要用户不点击“刷新题目/再测一次”，那么无论页面是否刷新，小测栏始终展示的都是上一次小测的结果，这是因为quiz_status始终都是completed状态。
    -- 但如果用户点击“刷新题目/再测一次”，此时系统生成新的题目存储到pending_quiz中，quiz_state重新变为pending状态。而只要quiz_state的值为pending，那么显示的就是新题而不是就题。
    -- 展示的究竟是新题还是旧题，是由状态status决定的。
    
  marked_complete BOOLEAN NOT NULL DEFAULT FALSE,  -- 用户是否标记主题已完成
  completed_at TIMESTAMPTZ,	-- 主题完成时间
  last_visited_at TIMESTAMPTZ,  -- 用户最近一次访问主题的时间
  created_at TIMESTAMPTZ DEFAULT now(), -- 进度开始时间
  updated_at TIMESTAMPTZ DEFAULT now(),	-- 进度更新时间
    
    
  PRIMARY KEY (user_id, topic_id)	-- 每个进度是唯一的，而且按照user->topic搜索
);
```





# 5) AI对话记录——会话与消息

## 5.1 基本表结构

- 一个用户对应多个会话，会话可分为**全局会话**（可多建）和**主题会话**（唯一），一个会话包含多个对话消息。

- 使用一个**chat_sessions表**用来存储所有会话，使用**chat_messages表**用来存储所有会话中的信息，通过外键来建立关系。

#### （1）chat_sessions表

```sql
-- 定义chat类型：可以是全局会话，也可以是主题会话
CREATE TYPE chat_scope AS ENUM ('global', 'topic');

-- chat_sessions：对话会话表。一个会话就是一个AI对话历史记录。
CREATE TABLE chat_sessions (
  id UUID PRIMARY KEY,	
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,	-- 会话属于哪个用户 
  scope chat_scope NOT NULL,					-- 属于全局还是主题
  topic_id UUID REFERENCES topics(id),          -- 如果是主题会话，属于哪个主题
  title TEXT,									-- 会话名称（用户来取）
    
  token_count INT,   	-- 记录该会话的总 token 数，便于控制上下文长度；            
  message_count INT,    -- 记录消息条数，加速分页、摘要判断；          
  summary TEXT,         -- 当前压缩后的历史摘要文本（对第 1 ~ N 条消息的总结）；              
  summary_updated_at TIMESTAMPTZ,	  -- 摘要最近更新时间； 
  summarized_upto_message_id UUID,    -- 标记目前 summary 已总结到哪条消息（消息 ID）；	
  		--  这样设计的目的是：
			-- 避免每次拼接上下文都聚合所有历史；
			-- 快速判断“是否需要摘要”，和“尾巴从哪开始”。
        
  last_active_at TIMESTAMPTZ DEFAULT now(),  -- 该会话上次活跃时间，用于展示时排序；
  created_at TIMESTAMPTZ DEFAULT now()  -- 会话创建时间
);

-- 对每个用户，限定同一个主题下只能有一个“主题会话”
CREATE UNIQUE INDEX ux_topic_chat_once
ON chat_sessions (user_id, topic_id)
WHERE scope = 'topic';

-- 建立聚合索引加快查询，因为在前端需要按最近访问顺序展示会话列表
CREATE INDEX idx_sessions_user_last_active
ON chat_sessions (user_id, last_active_at DESC);


```

#### （2）chat_messages表

``` sql
CREATE TYPE role AS ENUM ('user', 'ai');

-- chat_messages: 消息表。存储所有对话消息
CREATE TABLE chat_messages (
  id UUID PRIMARY KEY,
  session_id UUID REFERENCES chat_sessions(id) ON DELETE CASCADE,	-- 消息属于哪个会话
  role role NOT NULL,                           -- 表示消息角色：用户消息 or AI 回复。   
  content TEXT NOT NULL,						-- 文字内容（包括当前的语言
  token_count INT,  				-- 每条消息的 token 长度，可通过分词器计算
  meta JSONB,                                   -- 用于携带文件、图片url，以及其他元信息
  created_at TIMESTAMPTZ DEFAULT now()	-- 消息创建时间，用于按时间顺序排序消息用于展示
);

-- 按所属会话，创建时间建立聚合索引，加速消息检索
CREATE INDEX ON chat_messages(session_id, created_at);

-- 向量索引（消息/摘要）
ALTER TABLE chat_messages ADD COLUMN embedding vector(1536);
CREATE INDEX ON chat_messages USING ivfflat (embedding vector_cosine_ops);

-- 如果消息非常多，那么即便有索引，查询也会变慢。这个时候只需要把chat_messages做时间分区，然后按月建子表即可。
```

## 5.2 会话定期摘要

由于调用模型API都是单次调用，故模型一方不保存上下文。因此每次必须携带会话的上下文。但是，长对话中，如果把所有消息都带入上下文：

- token 占用高，易超限
- 前面内容模型“遗忘”
- 性能低，响应慢

**所以我们希望：**

> **随着对话变长，把历史消息压缩成 summary，保留最近几条原文消息用于语境，形成上下文简化结构：**
> `系统提示 + 压缩 summary + 原始尾部消息`

#### 每条消息单独记录 `token_count`

```sql
chat_messages (
  token_count INT,  -- 每条消息的 token 长度
)
```

------

#### 每个会话记录累积状态（在 `chat_sessions`）

```sql
chat_sessions (
  id UUID,
  token_count INT,              -- 累计 token 总数
  message_count INT,            -- 消息数
  summary TEXT,                 -- 历史摘要
  summary_updated_at TIMESTAMPTZ,
  summarized_upto_message_id UUID, -- 已经总结到哪条
  ...
)
```

这样可以快速判断是否需要总结，以及拼接上下文时用什么。

------

#### 只对历史消息做“滚动摘要”，保留尾巴

> 所有上下文拼装都遵循这个结构：

```
System prompt + chat_sessions.summary + 最近未总结的原始消息（称为尾巴 Tail）
```

> 举例拼接：

- S（summary）：总结到 20 条消息
- W（尾巴）：第 21~25 条原文消息
- 当前新消息：第 26 条

------

#### 摘要过程是“替换”，不是“追加”

- 摘要是覆盖式，不是加越来越多内容。
- 每次生成的 summary 是“截至第 N 条消息为止的最小必要信息总结”。
- 每次更新 `summary`、`summary_updated_at` 和 `summarized_upto_message_id`

------

#### 什么时候触发摘要？

不建议每次都总结，推荐设置触发阈值，例如：

| 条件                                     | 说明                               |
| ---------------------------------------- | ---------------------------------- |
| `chat_session.token_count > 3000`        | 会话整体过长，摘要压缩             |
| `tail_token_count > 1200`                | 尾巴消息太长，压缩旧的             |
| `time_since(summary_updated_at) > 2分钟` | 避免频繁总结（加 hysteresis 回落） |

**触发后：**

- 找出 `summarized_upto_message_id` 之后的旧消息
- 取若干条拼接 summary 做 prompt
- 调用 LLM 生成新摘要，更新到会话表
- 删除尾部中被包含进 summary 的部分

## 5.3 上传文件图片

#### 上传文件图片前后端流程

**1. 用户选择上传文件或图片**
 → 前端读取文件（如 `.pdf`, `.jpg`, `.docx` 等）

**2. 前端将文件通过 API 上传到后端**（例如：`/api/upload`）

- 后端接收文件

- 存到指定存储位置（本地磁盘、AWS S3、OSS 等）

- 获得文件 URL（如 `https://cdn.example.com/user_files/abc.pdf`）

  **然后在 `user_files` 表中写入一条记录（参见8 文件上传与通知）**，用于：

  - 记录和管理文件；
  - 让前端获取可用链接（`storage_url`）；
  - 记录该文件是谁上传的、何时上传、关联到哪个会话等。

**3. 后端返回文件信息（含 URL）给前端**
 前端就能：

- 显示预览（如图片）
- 将 URL 插入对话消息（即放进 `chat_messages.meta`

#### 文件存放三种典型方案

| 存储方式                | `storage_url` 示例                        | 优点                   | 缺点                 |
| ----------------------- | ----------------------------------------- | ---------------------- | -------------------- |
| 本地文件系统            | `/uploads/abc.png`                        | 简单，部署方便         | 扩展性差             |
| CDN 网关 + 本地         | `https://cdn.example.com/files/abc.png`   | 快速、安全、用户体验好 | 需额外部署           |
| 云对象存储（如 AWS S3） | `https://bucket.s3.amazonaws.com/abc.png` | 弹性扩展，稳定         | 配置略复杂，成本稍高 |

通常推荐使用云对象存储或CDN接入，尤其是生产环境。

## 5.4 消息表分区策略

按月/按年给 `chat_messages` 做**时间分区**（PostgreSQL 支持 native 分区）：

```sql
CREATE TABLE chat_messages (
  id UUID,
  session_id UUID,
  ...
  created_at TIMESTAMPTZ NOT NULL
) PARTITION BY RANGE (created_at);
```

然后按月建子表：

```sql
CREATE TABLE chat_messages_2025_08
  PARTITION OF chat_messages
  FOR VALUES FROM ('2025-08-01') TO ('2025-09-01');
```

- 分区后查询会只扫相关子表，性能提升非常明显。



# 6) 情景模拟（练习回合与评分）（先放着不管）

```sql
CREATE TABLE scenarios (
  id UUID PRIMARY KEY,
  topic_id UUID REFERENCES topics(id) ON DELETE CASCADE,
  title TEXT NOT NULL,
  prompt_template TEXT,              -- 起始情景 & 指令
  rubric JSONB                       -- 评价维度与权重
);

CREATE TABLE scenario_attempts (
  id UUID PRIMARY KEY,
  scenario_id UUID REFERENCES scenarios(id) ON DELETE CASCADE,
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  started_at TIMESTAMPTZ DEFAULT now(),
  completed_at TIMESTAMPTZ,
  score NUMERIC,
  ai_feedback TEXT                   -- 2-3条建议等 
);

CREATE TABLE scenario_messages (
  id UUID PRIMARY KEY,
  attempt_id UUID REFERENCES scenario_attempts(id) ON DELETE CASCADE,
  role TEXT NOT NULL,                -- user/assistant
  content TEXT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT now()
);
```

------



# 7) 知识库/RAG

```sql
CREATE TABLE documents (
  id UUID PRIMARY KEY,
  title TEXT,						-- 文档标题
  source TEXT,                       -- 知识库url或上传来源
  topic_id UUID REFERENCES topics(id),	-- 知识库属于哪一个主题
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT now()	-- 创建时间
);

CREATE TABLE document_chunks (
  id UUID PRIMARY KEY,
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  chunk_index INT NOT NULL,
  content TEXT NOT NULL,
  embedding VECTOR(1536)             -- pgvector
);
CREATE INDEX ON document_chunks USING ivfflat (embedding vector_cosine_ops);
```

------

## 7.1 什么是RAG

**一句话**：RAG（Retrieval-Augmented Generation）=「先检索，后生成」。
 让 LLM 在回答前，**去你的外部知识库把最相关的片段找回来**，作为“证据/上下文”拼进提示词里，再让模型生成答案。

**流程图：**用户问题 → 向量化 → 相似度检索 Top-K 文档片段 → 组装上下文 → 送入 LLM → 生成答案（可带引用）

**不需要任何训练操作，非常简单，就是每次发送用户对话都提供最接近的知识库。**

##  7.2  RAG 使用流程

### 1. 文档预处理

- 接收 PDF、Word、HTML 或 Markdown
- 抽取纯文本 → 拆分成 chunks（段落）
- 每个 chunk 生成语义向量 embedding
- 入库：存入 `document_chunks` 表

------

### 2. 用户提问处理（实时）

- 接收用户问题
- 把问题转成向量 embedding
- 检索出 top-K 最相似的 chunks
- 拼装上下文：系统提示 + 检索结果 + 用户提问
- 喂给 OpenAI（或其他）生成回复

## 7.3 怎么把整个文档拆段

有现成的拆分工具。

| 参数              | 推荐值                                       |
| ----------------- | -------------------------------------------- |
| 单 chunk token 数 | 200 ~ 500 tokens                             |
| 是否重叠          | 是，建议 10~50 tokens                        |
| 按什么拆          | 按段落、换行、句子、标题拆优先，不要中断句子 |

## 7.4 怎么给每个 chunk 生成向量

每个 chunk 内容都会用 embedding 模型转成向量。

可以使用用 OpenAI 的 embedding API：

```
text-embedding-3-small→ 输出 1536 维向量
```

------

## 7.5 怎么快速向量检索？

------

### **“语义相似度 = 向量点积/余弦距离”**

但不用一条条chunk拿出来点积，只需要使用向量索引，就可以快速得到最接近的Top-K知识块。

**使用 PostgreSQL 插件 [pgvector](https://github.com/pgvector/pgvector?utm_source=chatgpt.com)**：

```sql
SELECT * FROM document_chunks
ORDER BY embedding <#> :query_embedding
LIMIT 5;
```

- `<#>` 是“cosine 距离”运算符
- 会自动用 ivfflat 索引加速

## 7.6 简单总结和提炼

- **其实原理非常简单，就是用户每次发送对话，都根据用户的文字找到语义最相近的几个知识块一起发送给AI，提高AI回答的针对性。这些知识块可以结合提示词写在token里。**
- **具体来说，每次用户发送信息，实际发送给Chat GPT发送的信息包括以下内容：**
  - **用户本次聊天发送的信息**
  - **之前对话记录的摘要**
  - **最近 N 条未摘要的原始对话（消息尾巴）**
  - **系统提示词：比如指出哪些是摘要，哪些是原始对话，要回答的是用户哪个问题，甚至使用什么样的语气等，甚至指示它不要透露自己是ChatGPT等等**
  - **通过RAG获得的Top-K知识片段**
  - **其他元信息：如图片、文件的url，当前处于哪个模块，用户的身份等等**
- **这些内容有的是放在JSON，有的是放在文本content中的。具体怎么组织要看Chat GPT的API的要求。暂且还没去了解。**



# 8) 文件上传

------

``` sql
CREATE TYPE file_visibility AS ENUM ('public', 'private');

CREATE TABLE files (
  id UUID PRIMARY KEY,
  -- 归属（谁的资源/属于哪个业务对象）
  owner_type TEXT NOT NULL,                    -- 'user' | 'topic' | 'system' | 'assessment' | 'chat'
  owner_id UUID,                               -- 对应对象的 id（system 可为空）
  kind TEXT NOT NULL,                          -- 'chat_attachment' | 'avatar' | 'topic_asset' | 'assessment_export' | ...
  -- 存储定位（不写死供应商 URL）
  provider TEXT NOT NULL,                      -- 'aws' | 'aliyun' | 'tencent' | 'minio' | 'local'
  bucket TEXT NOT NULL,                        -- 如 'prod-assets'
  region TEXT,                                 -- 如 'ap-southeast-2'
  object_key TEXT NOT NULL,                    -- 如 'user_uploads/abc123.pdf'
    
  -- 文件元数据
  file_name TEXT NOT NULL,
  mime_type TEXT NOT NULL,
  size BIGINT NOT NULL,
  etag TEXT,                                   -- S3 etag（便于校验）
  sha256 TEXT,                                 -- 内容哈希（去重/秒传）
  width INT, height INT,                       -- 图片
  duration_seconds NUMERIC,                    -- 音视频
  page_count INT,                              -- PDF 页数
  visibility file_visibility NOT NULL DEFAULT 'private',
  extra JSONB,                                 -- EXIF、OCR 结果、转码信息等
  created_at TIMESTAMPTZ DEFAULT now(),
  deleted_at TIMESTAMPTZ
);

-- 常用索引
CREATE UNIQUE INDEX ON user_files (bucket, object_key);
CREATE INDEX ON user_files (owner_type, owner_id);
CREATE INDEX ON user_files (kind);
CREATE INDEX ON user_files (visibility);
```

### 🧾 一类：**文件基本元信息**（文件本身的内容特征）

| 字段名             | 含义                                                  |
| ------------------ | ----------------------------------------------------- |
| `file_name`        | 原始文件名（用户上传时的名字）                        |
| `mime_type`        | 文件类型（如 image/png, application/pdf）             |
| `size`             | 字节大小                                              |
| `etag`             | 存储系统生成的校验码（如 S3 的 ETag）                 |
| `sha256`           | 文件内容的哈希值（去重/秒传用）                       |
| `width` / `height` | 图片的尺寸（适用于图片/视频）                         |
| `duration_seconds` | 音/视频的时长                                         |
| `page_count`       | PDF 的页数                                            |
| `extra`            | 存放扩展信息的 JSON（如 OCR、EXIF、变体、转码信息等） |

> ✅ 用途：用于展示、预览、二次处理、性能优化（首屏缩略图）、去重、类型识别等。

------

### 🧭 二类：**存储位置信息**（文件在哪里、怎么访问）

| 字段名       | 含义                                          |
| ------------ | --------------------------------------------- |
| `provider`   | 使用的对象存储平台（如 aws / aliyun / minio） |
| `bucket`     | 存储桶名                                      |
| `region`     | 存储区域（如 ap-southeast-2）                 |
| `object_key` | 文件路径/文件名（如 user_uploads/abc123.pdf） |

> ✅ 用途：拼接 CDN 地址访问、生成签名 URL、调存储 SDK 下载或删除。

------

### 📛 三类：**用途分类字段**（文件属于什么/干啥的）

| 字段名       | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| `kind`       | 文件类型/业务场景（如 avatar / chat_attachment / topic_asset / export_pdf） |
| `owner_type` | 所属业务对象类型（如 user / topic / assessment / system）    |
| `owner_id`   | 所属对象的 ID（如 user_id / topic_id 等）                    |

> ✅ 用途：权限校验、业务溯源、引用管理、清理策略（如某用户注销后清空文件）

------

### 🔐 四类：**访问控制**

| 字段名       | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| `visibility` | 'public' / 'private'：是否允许匿名访问（影响是否用签名 URL） |

> ✅ 用途：控制 CDN 是否缓存、是否走后端签名、是否匿名访问（如头像、封面图 vs 私密附件）

------

### 🕓 五类：**生命周期字段**

| 字段名       | 含义           |
| ------------ | -------------- |
| `created_at` | 创建时间       |
| `deleted_at` | 软删除标记时间 |

> ✅ 用途：回收机制、统计上传时间、是否有效、数据治理





## 一、为什么要有一个文件上传表？都存些什么内容？主题内容区文本采取Markdown格式，其中会引用图片，该怎么存？

### 1.1 该存哪些

- **用户和AI聊天时会上传文件**：聊天附件、图片、音视频等。 
- **用户会上传头像封面等**：头像、封面图。
- **系统生成类**：评测报告 PDF、成绩单导出、缩略图/波形图/预览图（如果有的话）。
- **内容资产类**：**主题知识内容区的图片**、插图、封面等。

### 1.2 存储模式

**采用S3对象存储 + CDN快速分发模式**。即不宜储存在数据库的文件都作为对象存到S3去，数据库里存的是文件的object key。具体原理请自行询问AI。要写得太多了。具体的知识点包括：什么是对象存储，写地址用逻辑域名什么意思，S3和CDN怎么结合，实际DNS是如何解析逻辑域名的，为什么要使用逻辑域名。

### 1.3 Markdown文档里的图片怎么处理？

**首先要交给S3对象存储。**

**其次，存储信息既要存储到files表，而markdown文档中也直接写逻辑域名+object_key**

**不要在 Markdown 里写死 S3 或某家 CDN 的完整 URL**。

**而是使用：逻辑域名 + object_key**
 在保存 Markdown 前，把图片统一变成：

```json
![](https://files.example.com/topic_assets/cover-xyz.png)	
    	// example.com就是我们网站注册的域名，files是我们选的文件上传的子域名
```

- 存库只是一段普通 Markdown；
- `files.example.com` 是你**自己的逻辑域名**（CNAME 到任何 CDN）；
- 将来换 CDN/换云，**只改 DNS**，旧内容全部生效；
- 私有内容可改为 `![](/files/<uuid>)`，由后端把 `<uuid>` 解析并 302 到签名 URL。



## 二、为什么存储etag和sha256

------

###  `etag` – 存储系统生成的校验码（通常是 MD5 或多块合成）

**作用：**

- 上传后校验是否一致（文件完整性校验）；
- 删除/覆盖/更新时对比是否是**原版本**；
- 云服务（如 S3）用它来标记“是否命中缓存”。

**建议：**

- 不作为全局去重依据（因为它在多块上传时变了）；
- 和 `sha256` 搭配使用，可作为上传后比对参考。

------

### 🔐 `sha256` – 自己算的文件内容哈希（可用于去重/秒传）

**核心作用：**

1. **秒传机制（“这个文件我以前传过”）**：
   - 上传前先计算 hash（前端或后端）；
   - 查数据库是否已有该 hash → 有则跳过上传（节省带宽 + 节省存储 + 省时间）；
2. **跨项目文件复用**；
3. **数据一致性比对**（避免同名文件内容不同）。

**可选算法：**

- `sha256`（安全，推荐）
- `md5`（轻便但可能冲突）
- `xxhash`（超快，用于非安全校验）



## 三、 sha256 - 在文件上传时避免重复存储

**目标**：**相同内容只存一次或不重复上传，形成了秒传的假象。**

### 例子 A｜“秒传”   

1. 前端先算 `sha256`（或把文件分片 hash），把 hash 发给你的后端。
2. 后端查库：
   - **存在**（同一 `sha256` 的对象已在 S3）：
     - 直接在 `user_files` 新建一条**元数据记录**，**指向已有的 `object_key`**（或指向一个 blob 记录），**不再上传**。
   - **不存在**：发一个上传 URL（**直传到 S3**），上传完**异步核对 sha256**，落库。
3. 结果：第二个人传同一份教材图，**1 秒搞定**，也不会多占一份存储。

### 例子 B｜“避免重复存储”

- 两个不同 `user_files` 记录（不同 UUID、不同归属）可以**指向同一个 S3 对象**（通过相同 `sha256` 找到同一 `object_key` 或同一 `blobs` 行）。
- 你实现“逻辑多处可用，物理只存一份”。

> ⚠️ 注意：**ETag 不能拿来做去重**（多分片、跨系统不一致）；**MD5 也不建议**（碰撞风险+和 S3 ETag 不稳定）。**去重就老老实实用 SHA-256。**



## 四、为什么数据库里要存 ETag？

**一句话定位：\**ETag 是“这个对象在\**存储系统里**当前版本的令牌”。把它存起来，能让你在很多地方**少走弯路、少花钱、少踩坑**：

1. **让你的 `/files/:id` 网关支持 304，不打 S3**
   - 你的前端或浏览器会带 `If-None-Match: <etag>` 来请求同一文件。
   - 你从库里把该文件的 ETag 取出来一比：**相同就直接 304**（不下发内容，也**不需要去 S3/CDN**），省带宽、省延迟、省钱。
   - 没存 ETag 的话，你要么只能每次转发到 S3（贵/慢），要么干脆不支持协商缓存（用户每次都拉）。
2. **“安全覆盖/删除”前的并发校验**
   - 要替换 S3 上的对象前（例如管理员在后台“替换教材图片”），先 `HEAD` 对象拿到当前 ETag，并与**库里记录的 ETag**对比：
     - **不一致**→ 说明这段时间对象被别人改过，**拒绝覆盖**或提示“请刷新后再试”，避免“把别人的新版本给盖回去了”。
3. **同步/对账/迁移时的轻量校验**
   - 做对象迁移或清理任务（跨桶/跨云/跨环境）时，你能用库里的 ETag 快速判断“是不是同一个版本”“需不需要拷贝/回源”。
   - （注意：多分片上传时 ETag ≠ 内容 MD5，但**版本是否变化**它是稳定可靠的。）
4. **日志/审计/排查问题**
   - 用户说“我看到的还是旧图”：你能一眼对比“客户端报上来的 ETag”和“库里 ETag / 源站 ETag”，定位是不是 CDN 未回源或你发错了签名 URL。

> 小结：**ETag≠内容哈希**，是“**版本令牌**”。DB 里保存它，最大的价值是**做条件请求（304）和并发保护**，减少不必要的 S3/CDN流量与事故。
>
> 

------

## 五、ETag 的“时间线”：它何时产生、何时入库、你在上传/展示时各做了什么？

下面把常见三条链路画清楚。你照着任何一种实现，都能知道 ETag 在哪里出现。

------

### A) 直传 S3（前端用预签名 URL），公开资源走 CDN

**步骤：**

1. 前端向你的后端要上传许可 → 你的后端返回 **S3 预签名 PUT/POST**（含桶、`object_key`）。
2. 前端把文件直接 PUT 到 S3。
   - 上传完成后，前端**回调你的后端**一个 “upload-complete”。
3. 你的后端在这个回调里对该对象做一个 **`HEAD` 请求**到 S3：
   - 取到 **ETag**、大小、MIME、最后修改时间等→ **写入 `user_files`**（或更新该行）。
4. 之后前端展示文件：
   - 直接用逻辑域名 + `object_key`：`https://files.example.com/...`（CDN 会和 S3 协商缓存；**你这时不需要用到库里的 ETag**）。
   - 浏览器在下一次请求时会带 `If-None-Match` 给 **CDN**，CDN 会按需**回源**确认是否变更。

**你做了什么？**

- 在 **“上传完成回调”** 里把 ETag 入库。
- 公开访问时你可以不出手，让 **浏览器 ↔ CDN ↔ S3** 自己玩协商缓存。

------

### B) 直传 S3 + **私有访问**（通过你的 `/files/:id` 网关签名或 302）

**步骤：**

1. 上传同 A；回调时 `HEAD` → 把 **ETag 写入库**（同 A）。
2. 用户访问 `/files/:id`：
   - 如果请求头带了 `If-None-Match`，你从库里拿到 ETag 一比：
     - **相同**→ 直接回 **`304 Not Modified`**，**不用去 S3**；
     - 不同/没有 → 生成一个**短期签名 URL**（S3 或 CloudFront），**302 重定向**给前端。
   - 你在 302 响应里**顺便回写当前 ETag**（或在 200 场景里设置），浏览器会记住它；下次还能命中你的 304。

**你做了什么？**

- **在你的网关里真正使用了 DB 里的 ETag**，实现**条件 GET**（304），把很多重复请求拦在你这里，**既省 CDN/S3 流量，也保证权限**。

------

### C) 服务器中转上传（不是预签名；你把文件先收下再上传 S3）

**步骤：**

1. 用户把文件 POST 到你的后端；你的后端再把它 `PutObject` 到 S3。
   - **S3 的响应里会直接带 ETag** → 你**立即入库**（省一次 `HEAD`）。
2. 展示阶段走 A 或 B 任一套即可（公开直链或私有网关）。

**你做了什么？**

- 上传成功的那一刻就拿到了 ETag → **立刻写库**，之后的展示逻辑同上。

------

### 其他问题：

**Q1：如果我整个站点都是“公开直链 + CDN”，那 DB 里存 ETag 有啥用？**

- 公开直链场景，确实可以**不用**；浏览器与 CDN 会自己带 ETag 协商。
- 但**一旦你有 `/files/:id` 网关（鉴权/限速/计费/下载统计/埋点/审核）**，或者后台要做**并发保护/迁移对账**，**库里 ETag 就很有用**。

**Q2：ETag 跟 SHA256 的关系？我啥时候用哪个？**

- **ETag**：存储系统“当前版本令牌”，用在**HTTP 条件请求（304/If-None-Match）**、**CDN 是否回源**、**并发保护**。
- **SHA256**：**内容指纹**，用在**去重/秒传/跨系统一致性**。
- 两者**互补**：**版本判断**看 ETag；**内容等价**看 SHA256。